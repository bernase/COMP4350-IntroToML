{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bernase/COMP4350-IntroToML/blob/main/ML1_adl%C4%B1_dosyan%C4%B1n_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Racing Circuit Curve Analyzer ðŸ"
      ],
      "metadata": {
        "id": "UYlwdoGKMkWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Melek Berna Åžerit ðŸ‘©ðŸ¼â€ðŸ’» *18070001027*\n",
        "*   DoÄŸu Alpay ðŸ‘¨ðŸ»â€ðŸ’» *19070001008*"
      ],
      "metadata": {
        "id": "S5EsZzARdrFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###     Importing Libraries & Loading the data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from keras import applications\n",
        "from keras.applications import ResNet50,ResNet101\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "metadata": {
        "id": "t9cNpaW7pNog"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###     Google Drive connection to access our dataset named DS\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "root_path = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "sys.path.append(root_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTOrGe-nqiEr",
        "outputId": "b4ca7658-db04-405a-ecb0-56ec3efac662"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"installing casa6 + cngi (takes a minute or two)...\")\n",
        "os.system(\"apt-get install libgfortran3\")\n",
        "os.system(\"pip install casatasks==6.3.0.48\")\n",
        "os.system(\"pip install casadata\")\n",
        "os.system(\"pip install cngi-prototype==0.0.91\")\n",
        "\n",
        "# Retrieve and extract demonstration datasets\n",
        "print('retrieving MS tarfiles...')\n",
        "!gdown -q --id 1N9QSs2Hbhi-BrEHx5PA54WigXt8GGgx1\n",
        "!tar -xzf sis14_twhya_calibrated_flagged.ms.tar.gz\n",
        "print('complete')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce9mw7pmp-OJ",
        "outputId": "a632e90f-e125-44a2-c647-6f63a5d04e8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing casa6 + cngi (takes a minute or two)...\n",
            "retrieving MS tarfiles...\n",
            "/usr/local/lib/python3.8/dist-packages/gdown/cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1N9QSs2Hbhi-BrEHx5PA54WigXt8GGgx1 \n",
            "\n",
            "tar (child): sis14_twhya_calibrated_flagged.ms.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###     DataSet\n",
        "dataset_folder_name = os.path.join(root_path, 'DS')   #our dataset folder named DS\n",
        "MODEL_FILENAME = root_path + \"model_cv.h5\"\n",
        "source_files = []\n",
        "class_labels = ['1', '2', '3', '4', '5', '6']\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "img_rows, img_cols = 720, 720  # input image dimensions\n",
        "train_path = os.path.join(dataset_folder_name, 'train')\n",
        "validation_path = os.path.join(dataset_folder_name, 'validation')\n",
        "test_path = os.path.join(dataset_folder_name, 'test')"
      ],
      "metadata": {
        "id": "x38mj2-btHHr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_between_folders(source, dest, split_rate):\n",
        "    global source_files\n",
        "    source_files = os.listdir(source)\n",
        "    if(len(source_files) != 0):\n",
        "        transfer_file_numbers = int(len(source_files)*split_rate)\n",
        "        transfer_index = random.sample(\n",
        "            range(0, len(source_files)), transfer_file_numbers)\n",
        "        for each_index in transfer_index:\n",
        "            shutil.move(os.path.join(source, str(source_files[each_index])), os.path.join(\n",
        "                dest, str(source_files[each_index])))\n",
        "\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "\n",
        "def transfer_all_class_between_folders(source, dest, split_rate):\n",
        "    for label in class_labels:\n",
        "        transfer_between_folders(os.path.join(dataset_folder_name, source, label),\n",
        "                                 os.path.join(\n",
        "                                     dataset_folder_name, dest, label),\n",
        "                                 split_rate)\n",
        "\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    f1_Score = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1_Score))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1_Score\n",
        "\n",
        "def get_nb_training():\n",
        "    path1 = '/content/drive/MyDrive/Colab Notebooks/DS2/train/1'\n",
        "    nb_1sample = len([entry for entry in os.listdir(path1) if os.path.isfile(os.path.join(path1, entry))])\n",
        "    path2 = '/content/drive/MyDrive/Colab Notebooks/DS2/train/2'\n",
        "    nb_2sample = len([entry for entry in os.listdir(path2) if os.path.isfile(os.path.join(path2, entry))])\n",
        "    path3 = '/content/drive/MyDrive/Colab Notebooks/DS2/train/3'\n",
        "    nb_3sample = len([entry for entry in os.listdir(path3) if os.path.isfile(os.path.join(path3, entry))])\n",
        "    path4 = '/content/drive/MyDrive/Colab Notebooks/DS2/train/4'\n",
        "    nb_4sample = len([entry for entry in os.listdir(path4) if os.path.isfile(os.path.join(path4, entry))])\n",
        "    path5 = '/content/drive/MyDrive/Colab Notebooks/DS2/train/5'\n",
        "    nb_5sample = len([entry for entry in os.listdir(path5) if os.path.isfile(os.path.join(path5, entry))])\n",
        "    path6 = '/content/drive/MyDrive/Colab Notebooks/DS2/train/6'\n",
        "    nb_6sample= len([entry for entry in os.listdir(path6) if os.path.isfile(os.path.join(path6, entry))])\n",
        "    return (nb_1sample + nb_2sample + nb_3sample + nb_4sample + nb_4sample + nb_5sample + nb_6sample)\n",
        "\n",
        "def get_nb_validation():\n",
        "    path1 = '/content/drive/MyDrive/Colab Notebooks/DS2/validation/1'\n",
        "    nb_1sample = len([entry for entry in os.listdir(path1) if os.path.isfile(os.path.join(path1, entry))])\n",
        "    path2 = '/content/drive/MyDrive/Colab Notebooks/DS2/validation/2'\n",
        "    nb_2sample = len([entry for entry in os.listdir(path2) if os.path.isfile(os.path.join(path2, entry))])\n",
        "    path3 = '/content/drive/MyDrive/Colab Notebooks/DS2/validation/3'\n",
        "    nb_3sample = len([entry for entry in os.listdir(path3) if os.path.isfile(os.path.join(path3, entry))])\n",
        "    path4 = '/content/drive/MyDrive/Colab Notebooks/DS2/validation/4'\n",
        "    nb_4sample = len([entry for entry in os.listdir(path4) if os.path.isfile(os.path.join(path4, entry))])\n",
        "    path5 = '/content/drive/MyDrive/Colab Notebooks/DS2/validation/5'\n",
        "    nb_5sample = len([entry for entry in os.listdir(path5) if os.path.isfile(os.path.join(path5, entry))])\n",
        "    path6 = '/content/drive/MyDrive/Colab Notebooks/DS2/validation/6'\n",
        "    nb_6sample= len([entry for entry in os.listdir(path6) if os.path.isfile(os.path.join(path6, entry))])\n",
        "    return (nb_1sample + nb_2sample + nb_3sample + nb_4sample + nb_4sample + nb_5sample + nb_6sample)"
      ],
      "metadata": {
        "id": "dX8ZHRlUue_u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if test folder is empty\n",
        "transfer_all_class_between_folders('test', 'train', 1.0)"
      ],
      "metadata": {
        "id": "lGMv2wh_uqsb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_all_class_between_folders('train', 'test', 0.20)"
      ],
      "metadata": {
        "id": "s7_gXS8Uwnhy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_name_with_labels(folder_name, dataset_type='train'):\n",
        "    source_files = os.listdir(os.path.join(dataset_folder_name, dataset_type, folder_name))\n",
        "    y_label = 0\n",
        "    for i in range(len(class_labels)):\n",
        "        if(folder_name == class_labels[i]):\n",
        "            y_label = i\n",
        "    for val in source_files:\n",
        "        X.append(val)\n",
        "        Y.append(y_label)"
      ],
      "metadata": {
        "id": "dqrKBUVHwwcW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(class_labels)):\n",
        "    prepare_name_with_labels(class_labels[i])"
      ],
      "metadata": {
        "id": "PP7Y7Y5mwwxc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)"
      ],
      "metadata": {
        "id": "sMaHQWWMwxDK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###     Model Config\n",
        "batch_size = 10\n",
        "epoch = 2\n",
        "n_split = 5\n",
        "num_of_channels = 3\n",
        "number_of_class_labels = len(class_labels)\n",
        "\n",
        "data_kfold = pd.DataFrame()\n",
        "\n",
        "main_pred = []\n",
        "error = []\n",
        "data_kfold = pd.DataFrame()"
      ],
      "metadata": {
        "id": "-93mY_ofw-vu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def get_model():\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                     activation=activation_function, input_shape=(img_rows, img_cols, num_of_channels)))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(32, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(16, (3, 3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(16, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(32, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(16, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(number_of_class_labels, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_model()\n",
        "\"\"\"\n",
        "\n",
        "def get_model():\n",
        "    base_model =applications.ResNet50(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, num_of_channels))\n",
        "    add_model = Sequential()\n",
        "    add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    add_model.add(Dropout(0.3))\n",
        "    add_model.add(Dense(64, activation='relu'))\n",
        "    add_model.add(Dropout(0.4))\n",
        "\n",
        "    add_model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ],
      "metadata": {
        "id": "64MoLJuAw-_3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "fold_num = 0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    # First cut all images from validation to train (if any exists)\n",
        "    transfer_all_class_between_folders('validation', 'train', 1.0)\n",
        "    fold_num += 1\n",
        "    print(\"Results for fold\", fold_num)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for each_index in range(len(X_val)):\n",
        "        class_label = ''\n",
        "        for i in range(len(class_labels)):\n",
        "            if(Y_val[each_index] == i):\n",
        "                class_label = class_labels[i]\n",
        "        # Then, copy the validation images to the validation folder\n",
        "        shutil.move(os.path.join(dataset_folder_name, 'train', class_label, X_val[each_index]),\n",
        "                    os.path.join(dataset_folder_name, 'validation', class_label, X_val[each_index]))\n",
        "\n",
        "    # k-fold\n",
        "    kfold = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=42)\n",
        "    # Variable for keeping count of split we are executing\n",
        "    j = 0\n",
        "\n",
        "    # K-fold Train and test for each split\n",
        "    for train_index, val_index in list(kfold.split(X,Y)):\n",
        "        X_train, X_val = X[train_index], X[val_index]\n",
        "        j+=1\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.20,\n",
        "        shear_range = 0.2,\n",
        "        fill_mode=\"nearest\")\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "\n",
        "    # fit model\n",
        "    history = model.fit(train_generator,\n",
        "                        steps_per_epoch=get_nb_training() // batch_size,\n",
        "                        epochs=epoch,\n",
        "                        validation_data=validation_generator, \n",
        "                        validation_steps=get_nb_validation() // batch_size)\n",
        "\n",
        "    #gc.collect()\n",
        "    predictions = model.predict(validation_generator, verbose=1)\n",
        "    y_predictions = np.argmax(predictions, axis=1)\n",
        "    true_classes = validation_generator.classes\n",
        "    \n",
        "    # evaluate validation performance\n",
        "    print(\"***Performance on Validation data***\")\n",
        "    val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW8LqXvQw_Na",
        "outputId": "218d1798-0bc4-4f6e-918a-80fbf112b740"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for fold 1\n",
            "Found 66 images belonging to 6 classes.\n",
            "Found 22 images belonging to 6 classes.\n",
            "Epoch 1/2\n",
            " 7/11 [==================>...........] - ETA: 4:33 - loss: 22.1012 - accuracy: 0.1667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 22 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 502s 41s/step - loss: 22.1012 - accuracy: 0.1667\n",
            "3/3 [==============================] - 38s 10s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.13636363636363635\n",
            "Precision : 0.018595041322314047\n",
            "f1Score : 0.03272727272727273\n",
            "[[0 0 0 0 0 4]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 3]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 3]]\n",
            "Results for fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 66 images belonging to 6 classes.\n",
            "Found 22 images belonging to 6 classes.\n",
            "Epoch 1/2\n",
            " 7/11 [==================>...........] - ETA: 4:23 - loss: 9.4404 - accuracy: 0.3333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 22 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 471s 40s/step - loss: 9.4404 - accuracy: 0.3333\n",
            "3/3 [==============================] - 42s 10s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.18181818181818182\n",
            "Precision : 0.03305785123966942\n",
            "f1Score : 0.055944055944055944\n",
            "[[0 0 0 0 0 3]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 3]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 4]]\n",
            "Results for fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 66 images belonging to 6 classes.\n",
            "Found 22 images belonging to 6 classes.\n",
            "Epoch 1/2\n",
            " 7/11 [==================>...........] - ETA: 4:24 - loss: 3.2028 - accuracy: 0.3485"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 22 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 472s 40s/step - loss: 3.2028 - accuracy: 0.3485\n",
            "3/3 [==============================] - 37s 10s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.18181818181818182\n",
            "Precision : 0.03305785123966942\n",
            "f1Score : 0.055944055944055944\n",
            "[[0 0 0 0 0 3]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 3]\n",
            " [0 0 0 0 0 4]\n",
            " [0 0 0 0 0 4]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============TEST RESULTS============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False \n",
        ")\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "y_predictions = np.argmax(predictions, axis=1)\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "test_acc, test_prec, test_fScore = my_metrics(true_classes, y_predictions)\n",
        "model.save(MODEL_FILENAME)"
      ],
      "metadata": {
        "id": "ypR8PSXew_cP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f3bb47-8f18-4e8e-d532-5646ed9b4144"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============TEST RESULTS============\n",
            "Found 12 images belonging to 6 classes.\n",
            "2/2 [==============================] - 28s 4s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  : 0.16666666666666666\n",
            "Precision : 0.027777777777777776\n",
            "f1Score : 0.047619047619047616\n",
            "[[0 0 0 0 0 2]\n",
            " [0 0 0 0 0 2]\n",
            " [0 0 0 0 0 2]\n",
            " [0 0 0 0 0 2]\n",
            " [0 0 0 0 0 2]\n",
            " [0 0 0 0 0 2]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}